{"cells":[{"cell_type":"markdown","id":"7607bdb2-1707-4361-a984-1c443fe84370","metadata":{},"source":["# Introduction to TensorFlow in Python\n"]},{"cell_type":"code","execution_count":3,"id":"7f26dd6a-20aa-4d19-8d3f-b8f64fba1821","metadata":{"executionTime":206,"lastSuccessfullyExecutedCode":"# Import any packages you want to use here\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport keras\n\n# Read csv file as credit_card using pandas\ncredit_card = pd.read_csv('datasets/uci_credit_card.csv')\ncredit_numpy = credit_card.loc[:,['EDUCATION','MARRIAGE','AGE','BILL_AMT1']].to_numpy()\n\nhouse = pd.read_csv('datasets/kc_house_data.csv')\n\nslmnist = pd.read_csv('datasets/slmnist.csv')"},"outputs":[],"source":["# Import any packages you want to use here\n","import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","import keras\n","\n","# Read csv file as credit_card using pandas\n","credit_card = pd.read_csv('datasets/uci_credit_card.csv')\n","credit_numpy = credit_card.loc[:,['EDUCATION','MARRIAGE','AGE','BILL_AMT1']].to_numpy()\n","\n","house = pd.read_csv('datasets/kc_house_data.csv')\n","\n","slmnist = pd.read_csv('datasets/slmnist.csv')"]},{"cell_type":"markdown","id":"062e3cce-2b5a-460f-8f93-e4767924ef33","metadata":{},"source":["# Chapter 1 : Introduction to TensorFlow"]},{"cell_type":"markdown","id":"b1d3e00d-2cb2-495b-99d8-850b5514db6f","metadata":{},"source":["## Defining data as constants"]},{"cell_type":"code","execution_count":48,"id":"829f8270-c84d-41ce-9ae2-5268310051d3","metadata":{"executionTime":38,"lastSuccessfullyExecutedCode":"# Convert the credit_numpy array into a tensorflow constant\ncredit_constant = constant(credit_numpy)\n\n# Print constant datatype\nprint('\\n The datatype is:', credit_constant.dtype)\n\n# Print constant shape\nprint('\\n The shape is:', credit_constant.shape)"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n"," The datatype is: <dtype: 'float64'>\n","\n"," The shape is: (30000, 4)\n"]}],"source":["# Convert the credit_numpy array into a tensorflow constant\n","credit_constant = constant(credit_numpy)\n","\n","# Print constant datatype\n","print('\\n The datatype is:', credit_constant.dtype)\n","\n","# Print constant shape\n","print('\\n The shape is:', credit_constant.shape)"]},{"cell_type":"markdown","id":"b88d9500-2d14-465e-b2f9-5de5a9af5c01","metadata":{},"source":["## Defining variables"]},{"cell_type":"code","execution_count":11,"id":"acf5f313-35d4-414b-81ae-95b48e43bb1c","metadata":{"executionTime":23,"lastSuccessfullyExecutedCode":"# Define the Variable() function\ndef Variable(x):\n    return(tf.Variable(x))"},"outputs":[],"source":["# Define function\n","def Variable(x):\n","    return(tf.Variable(x))"]},{"cell_type":"code","execution_count":9,"id":"b1b549b7-a329-4a9b-884c-79adc70bdc05","metadata":{"executionTime":38,"lastSuccessfullyExecutedCode":"def Variable(x):\n    return(tf.Variable(x))\n\n# Define the 1-dimensional variable A1\nA1 = Variable([1, 2, 3, 4])\n\n# Print the variable A1\nprint('\\n A1: ', A1)\n\n# Convert A1 to a numpy array and assign it to B1\nB1 = A1.numpy()\n\n# Print B1\nprint('\\n B1: ', B1)"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n"," A1:  <tf.Variable 'Variable:0' shape=(4,) dtype=int32, numpy=array([1, 2, 3, 4], dtype=int32)>\n","\n"," B1:  [1 2 3 4]\n"]}],"source":["# Define the 1-dimensional variable A1\n","A1 = Variable([1, 2, 3, 4])\n","\n","# Print the variable A1\n","print('\\n A1: ', A1)\n","\n","# Convert A1 to a numpy array and assign it to B1\n","B1 = A1.numpy()\n","\n","# Print B1\n","print('\\n B1: ', B1)"]},{"cell_type":"markdown","id":"4a1c4a6e-9868-4c3f-86f3-9b9bc1eb4bd6","metadata":{},"source":["## Performing element-wise multiplication"]},{"cell_type":"code","execution_count":13,"id":"e773b34a-3ddc-4251-9bea-56b6ab810ee6","metadata":{"executionTime":32,"lastSuccessfullyExecutedCode":"# Define function\ndef constant(x):\n    return(tf.constant(x))\n\ndef ones_like(x):\n    return(tf.ones_like(x))\n\ndef multiply(x, y):\n    return(tf.multiply(x, y))"},"outputs":[],"source":["# Define function\n","def constant(x):\n","    return(tf.constant(x))\n","\n","def ones_like(x):\n","    return(tf.ones_like(x))\n","\n","def multiply(x, y):\n","    return(tf.multiply(x, y))"]},{"cell_type":"code","execution_count":16,"id":"1bb39362-8ed6-4317-b86a-01a8a5898445","metadata":{"executionTime":36,"lastSuccessfullyExecutedCode":"# Define tensors A1 and A23 as constants\nA1 = constant([1, 2, 3, 4])\nA23 = constant([[1, 2, 3], [1, 6, 4]])\n\n# Define B1 and B23 to have the correct shape\nB1 = ones_like(A1)\nB23 = ones_like(A23)\n\n# Perform element-wise multiplication\nC1 = multiply(A1, B1)\nC23 = multiply(A23, B23)\n\n# Print the tensors C1 and C23\nprint('\\n C1: {}'.format(C1.numpy()))\nprint('\\n C23: {}'.format(C23.numpy()))\n"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n"," C1: [1 2 3 4]\n","\n"," C23: [[1 2 3]\n"," [1 6 4]]\n"]}],"source":["# Define tensors A1 and A23 as constants\n","A1 = constant([1, 2, 3, 4])\n","A23 = constant([[1, 2, 3], [1, 6, 4]])\n","\n","# Define B1 and B23 to have the correct shape\n","B1 = ones_like(A1)\n","B23 = ones_like(A23)\n","\n","# Perform element-wise multiplication\n","C1 = multiply(A1, B1)\n","C23 = multiply(A23, B23)\n","\n","# Print the tensors C1 and C23\n","print('\\n C1: {}'.format(C1.numpy()))\n","print('\\n C23: {}'.format(C23.numpy()))\n"]},{"cell_type":"markdown","id":"df5d4af9-0c24-41b3-bcb3-b7723a341405","metadata":{},"source":["## Making predictions with matrix multiplication"]},{"attachments":{},"cell_type":"markdown","id":"fff6e7a0-0642-4cb5-8258-898d3f3d2d65","metadata":{},"source":["The matrix of input data, <b>features</b>, contains two columns: education level and age. The target vector, <b>bill</b>, is the size of the credit card borrower's bill. <br> This process will yield a vector of parameters that can be multiplied by the input data to generate predictions</br>\n","<img src=\"images/credit-card.png\" \n","     width=\"400\" \n","     height=\"500\" />"]},{"cell_type":"code","execution_count":18,"id":"254e127c-4ee7-4016-a0a5-7da24dd12b03","metadata":{"executionTime":25,"lastSuccessfullyExecutedCode":"# Define function\ndef matmul(x, y):\n    return (tf.matmul(x, y))"},"outputs":[],"source":["# Define function\n","def matmul(x, y):\n","    return (tf.matmul(x, y))"]},{"cell_type":"code","execution_count":19,"id":"3645bd25-3734-4f82-8b2c-8d2c4b6efb34","metadata":{"executionTime":61,"lastSuccessfullyExecutedCode":"# Define features, params, and bill as constants\nfeatures = constant([[2, 24], [2, 26], [2, 57], [1, 37]])\nparams = constant([[1000], [150]])\nbill = constant([[3913], [2682], [8617], [64400]])\n\n# Compute billpred using features and params\nbillpred = matmul(features, params)\n\n# Compute and print the error\nerror = bill - billpred\nprint(error.numpy())"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[-1687]\n"," [-3218]\n"," [-1933]\n"," [57850]]\n"]}],"source":["# Define features, params, and bill as constants\n","features = constant([[2, 24], [2, 26], [2, 57], [1, 37]])\n","params = constant([[1000], [150]])\n","bill = constant([[3913], [2682], [8617], [64400]])\n","\n","# Compute billpred using features and params\n","billpred = matmul(features, params)\n","\n","# Compute and print the error\n","error = bill - billpred\n","print(error.numpy())"]},{"attachments":{},"cell_type":"markdown","id":"03b9fdee-c061-45a0-9dd7-aa6b88025911","metadata":{},"source":["## Optimizing with gradients <br> </br>\n","<img src=\"images/plot.png\" \n"," />\n"]},{"cell_type":"code","execution_count":23,"id":"df8838a2-ded7-45b7-90eb-b69f8359db0f","metadata":{"executionTime":35,"lastSuccessfullyExecutedCode":"# Define function\ndef Variable(x):\n    return(tf.Variable(x))\n\ndef multiply(x, y):\n    return(tf.multiply(x, y))\n"},"outputs":[],"source":["# Define function\n","def Variable(x):\n","    return(tf.Variable(x))\n","\n","def multiply(x, y):\n","    return(tf.multiply(x, y))\n"]},{"cell_type":"code","execution_count":19,"id":"e0e0048a-df7a-4f40-bfe7-36736a6f8688","metadata":{"executionTime":30,"lastSuccessfullyExecutedCode":"def compute_gradient(x0):\n  \t# Define x as a variable with an initial value of x0\n\tx = Variable(x0)\n\twith tf.GradientTape() as tape:\n\t\ttape.watch(x)\n        # Define y using the multiply operation\n\t\ty = multiply(x, x)\n    # Return the gradient of y with respect to x\n\treturn tape.gradient(y, x).numpy()\n\n# Compute and print gradients at x = -1, 1, and 0\nprint(compute_gradient(-1.0))\nprint(compute_gradient(1.0))\nprint(compute_gradient(0.0))"},"outputs":[{"name":"stdout","output_type":"stream","text":["-2.0\n","2.0\n","0.0\n"]}],"source":["def compute_gradient(x0):\n","  \t# Define x as a variable with an initial value of x0\n","\tx = Variable(x0)\n","\twith tf.GradientTape() as tape:\n","\t\ttape.watch(x)\n","        # Define y using the multiply operation\n","\t\ty = multiply(x, x)\n","    # Return the gradient of y with respect to x\n","\treturn tape.gradient(y, x).numpy()\n","\n","# Compute and print gradients at x = -1, 1, and 0\n","print(compute_gradient(-1.0))\n","print(compute_gradient(1.0))\n","print(compute_gradient(0.0))"]},{"cell_type":"markdown","id":"12368160-4def-4231-b26a-0035cf4a9ff1","metadata":{},"source":[]},{"cell_type":"code","execution_count":34,"id":"196b97ad-cccf-4490-a198-f7e058538b67","metadata":{"executionTime":29,"lastSuccessfullyExecutedCode":"# Define function\ndef multiply(x, y):\n    return(tf.multiply(x, y))\n\ndef matmul(x, y):\n    return(tf.matmul(x, y))\n\ndef reshape(model, shape):\n    return(tf.reshape(model, shape))\n\ndef reduce_sum(output,):\n    return(tf.reduce_sum(output,))\n\nmodel = tf.constant([1, 0, -1], dtype=tf.float32)"},"outputs":[],"source":["# Define function\n","def multiply(x, y):\n","    return(tf.multiply(x, y))\n","\n","def matmul(x, y):\n","    return(tf.matmul(x, y))\n","\n","def reshape(model, shape):\n","    return(tf.reshape(model, shape))\n","\n","def reduce_sum(output,):\n","    return(tf.reduce_sum(output,))\n","\n","model = tf.constant([1, 0, -1], dtype=tf.float32)\n","letter = np.array([[1,0,1],[1,1,0],[1,0,1]]).astype('float32')"]},{"cell_type":"code","execution_count":44,"id":"a6718d99-c7f1-4933-94d7-2f2446d4470d","metadata":{"executionTime":29,"lastSuccessfullyExecutedCode":"# Reshape model from a 1x3 to a 3x1 tensor\nmodel = reshape(model, (3, 1))\n\n# Multiply letter by model\noutput = matmul(letter, model)\n\n# Sum over output and print prediction using the numpy method\nprediction = reduce_sum(output)\nprint(prediction.numpy())"},"outputs":[{"name":"stdout","output_type":"stream","text":["1.0\n"]}],"source":["# Reshape model from a 1x3 to a 3x1 tensor\n","model = reshape(model, (3, 1))\n","\n","# Multiply letter by model\n","output = matmul(letter, model)\n","\n","# Sum over output and print prediction using the numpy method\n","prediction = reduce_sum(output)\n","print(prediction.numpy())"]},{"cell_type":"markdown","id":"2a7d7dbe-c22a-444c-807e-f17f2bbd4ebf","metadata":{},"source":["# Chapter 2 : Linear models\n","## Load data using pandas"]},{"cell_type":"code","execution_count":46,"id":"f882f26c-5732-40d4-b8a5-c888d32998b2","metadata":{"executionTime":85,"lastSuccessfullyExecutedCode":"# Import pandas under the alias pd\nimport pandas as pd\n\n# Assign the path to a string variable named data_path\ndata_path = 'datasets/kc_house_data.csv'\n\n# Load the dataset as a dataframe named housing\nhousing = pd.read_csv(data_path)\n\n# Print the price column of housing\nprint(housing['price'])"},"outputs":[{"name":"stdout","output_type":"stream","text":["0        221900.0\n","1        538000.0\n","2        180000.0\n","3        604000.0\n","4        510000.0\n","           ...   \n","21608    360000.0\n","21609    400000.0\n","21610    402101.0\n","21611    400000.0\n","21612    325000.0\n","Name: price, Length: 21613, dtype: float64\n"]}],"source":["# Import pandas under the alias pd\n","import pandas as pd\n","\n","# Assign the path to a string variable named data_path\n","data_path = 'datasets/kc_house_data.csv'\n","\n","# Load the dataset as a dataframe named housing\n","housing = pd.read_csv(data_path)\n","\n","# Print the price column of housing\n","print(housing['price'])"]},{"cell_type":"markdown","id":"57d94da5-e102-42a1-9b36-0a28228c4bcc","metadata":{},"source":["## Setting the data type"]},{"cell_type":"code","execution_count":49,"id":"af5b271f-a39d-446e-b76d-218656498b74","metadata":{"executionTime":44,"lastSuccessfullyExecutedCode":"# Import numpy and tensorflow with their standard aliases\nimport numpy as np\nimport tensorflow as tf\n\n# Use a numpy array to define price as a 32-bit float\nprice = np.array(housing['price'], np.float32)\n\n# Define waterfront as a Boolean using cast\nwaterfront = tf.cast(housing['waterfront'], tf.bool)\n\n# Print price and waterfront\nprint(price)\nprint(waterfront)"},"outputs":[{"name":"stdout","output_type":"stream","text":["[221900. 538000. 180000. ... 402101. 400000. 325000.]\n","tf.Tensor([False False False ... False False False], shape=(21613,), dtype=bool)\n"]}],"source":["# Import numpy and tensorflow with their standard aliases\n","import numpy as np\n","import tensorflow as tf\n","\n","# Use a numpy array to define price as a 32-bit float\n","price = np.array(housing['price'], np.float32)\n","\n","# Define waterfront as a Boolean using cast\n","waterfront = tf.cast(housing['waterfront'], tf.bool)\n","\n","# Print price and waterfront\n","print(price)\n","print(waterfront)"]},{"attachments":{},"cell_type":"markdown","id":"052432db-bb50-44da-8870-faa73535f8fd","metadata":{},"source":["<img src=\"images/Common-Loss-Functions.png\" /> <br> </br>\n","<img src=\"images/Common-Loss-Functions2.png\" />\n","     "]},{"cell_type":"markdown","id":"6d43f9cc-9976-48ed-8bec-4d3c8a2deb3d","metadata":{},"source":["## Modifying the loss function"]},{"cell_type":"code","execution_count":72,"id":"377c60f8-f634-42e8-98a0-a575fecafb56","metadata":{"executionTime":34,"lastSuccessfullyExecutedCode":"features = tf.constant([1., 2., 3., 4., 5.], dtype=tf.float32)\ntargets = tf.constant([2., 4., 6., 8., 10.], dtype=tf.float32)\n\n# Initialize a variable named scalar\nscalar = tf.Variable(1.0, dtype = tf.float32)\n\n# Define the model\ndef model(scalar, features = features):\n  \treturn scalar * features\n\n# Define a loss function\ndef loss_function(scalar, features = features, targets = targets):\n\t# Compute the predicted values\n\tpredictions = model(scalar, features)\n    \n\t# Return the mean absolute error loss\n\treturn keras.losses.mae(targets, predictions)\n\n# Evaluate the loss function and print the loss\nprint(loss_function(scalar).numpy())"},"outputs":[{"name":"stdout","output_type":"stream","text":["3.0\n"]}],"source":["features = tf.constant([1., 2., 3., 4., 5.], dtype=tf.float32)\n","targets = tf.constant([2., 4., 6., 8., 10.], dtype=tf.float32)\n","\n","# Initialize a variable named scalar\n","scalar = tf.Variable(1.0, dtype = tf.float32)\n","\n","# Define the model\n","def model(scalar, features = features):\n","  \treturn scalar * features\n","\n","# Define a loss function\n","def loss_function(scalar, features = features, targets = targets):\n","\t# Compute the predicted values\n","\tpredictions = model(scalar, features)\n","    \n","\t# Return the mean absolute error loss\n","\treturn keras.losses.mae(targets, predictions)\n","\n","# Evaluate the loss function and print the loss\n","print(loss_function(scalar).numpy())"]},{"attachments":{},"cell_type":"markdown","id":"c18ce2fc-9e3b-4d40-8fc3-32d84039af75","metadata":{},"source":["## Linear Regression\n","<img src=\"images/Linear-Regression.png\" />"]},{"cell_type":"markdown","id":"d293e84d-8549-4527-ad0c-7332243de449","metadata":{},"source":["## Set up a linear regression"]},{"cell_type":"code","execution_count":null,"id":"0d181903-2ddb-4659-97b7-c0bb679e56fe","metadata":{},"outputs":[],"source":["# Define a linear regression model\n","def linear_regression(intercept, slope, features = size_log):\n","\treturn intercept + features*slope\n","\n","# Set loss_function() to take the variables as arguments\n","def loss_function(intercept, slope, features = size_log, targets = price_log):\n","\t# Set the predicted values\n","\tpredictions = linear_regression(intercept, slope, features)\n","    \n","    # Return the mean squared error loss\n","\treturn keras.losses.mse(targets, predictions)\n","\n","# Compute the loss for different slope and intercept values\n","print(loss_function(0.1, 0.1).numpy())\n","print(loss_function(0.1, 0.5).numpy())"]},{"cell_type":"markdown","id":"ba4472d0-b072-4359-847c-9800558ba118","metadata":{},"source":["result is\n","~~~ python\n","output:\n","    145.44653\n","    71.866\n","~~~"]},{"cell_type":"markdown","id":"8ee9736e-aefe-4d53-a043-fb10916a9ab8","metadata":{},"source":["## Train a linear model"]},{"cell_type":"code","execution_count":null,"id":"e39488fe-7903-4044-80a8-2bb37f64dbe2","metadata":{},"outputs":[],"source":["# Initialize an Adam optimizer with a learning rate of 0.5.\n","opt = keras.optimizers.Adam(0.5)\n","\n","for j in range(100):\n","\t# Apply minimize, pass the loss function, and supply the variables\n","\topt.minimize(lambda: loss_function(intercept, slope), var_list=[intercept, slope])\n","\n","\t# Print every 10th value of the loss\n","\tif j % 10 == 0:\n","\t\tprint(loss_function(intercept, slope).numpy())\n","\n","# Plot data and regression line\n","plot_results(intercept, slope)"]},{"attachments":{},"cell_type":"markdown","id":"1ede2e81-935f-446f-a29e-2612042a1c04","metadata":{},"source":["result is\n","~~~ python\n","output:\n","    9.669482\n","    11.726698\n","    1.1193314\n","    1.6605737\n","    0.7982884\n","    0.8017316\n","    0.6106565\n","    0.59997976\n","    0.5811015\n","    0.5576158\n","~~~\n","\n","<img src=\"images/Fitted-Regression-Line.png\" />\n"]},{"cell_type":"markdown","id":"2d311f9a-8350-415e-8a81-21bf66b6f6dc","metadata":{},"source":["## Multiple linear regression"]},{"cell_type":"code","execution_count":null,"id":"bfc181f8-f0de-49a1-8b4b-0962ef0748cf","metadata":{},"outputs":[],"source":["params = tf.Variable([0.1, 0.05, 0.02], dtype=tf.float32)\n","\n","# Define the linear regression model\n","def linear_regression(params, feature1 = size_log, feature2 = bedrooms):\n","\treturn params[0] + feature1*params[1] + feature2*params[2]\n","\n","# Define the loss function\n","def loss_function(params, targets = price_log, feature1 = size_log, feature2 = bedrooms):\n","\t# Set the predicted values\n","\tpredictions = linear_regression(params, feature1, feature2)\n","  \n","\t# Use the mean absolute error loss\n","\treturn keras.losses.mae(targets, predictions)\n","\n","# Define the optimize operation\n","opt = keras.optimizers.Adam()\n","\n","# Perform minimization and print trainable variables\n","for j in range(10):\n","\topt.minimize(lambda: loss_function(params), var_list=[params])\n","\tprint_results(params)"]},{"cell_type":"markdown","id":"583380ae-52f5-4b7e-818d-ea0b87d4067a","metadata":{},"source":["result is\n","~~~ python\n","output:\n","    loss: 12.418, intercept: 0.101, slope_1: 0.051, slope_2: 0.021\n","    loss: 12.404, intercept: 0.102, slope_1: 0.052, slope_2: 0.022\n","    loss: 12.391, intercept: 0.103, slope_1: 0.053, slope_2: 0.023\n","    loss: 12.377, intercept: 0.104, slope_1: 0.054, slope_2: 0.024\n","    loss: 12.364, intercept: 0.105, slope_1: 0.055, slope_2: 0.025\n","    loss: 12.351, intercept: 0.106, slope_1: 0.056, slope_2: 0.026\n","    loss: 12.337, intercept: 0.107, slope_1: 0.057, slope_2: 0.027\n","    loss: 12.324, intercept: 0.108, slope_1: 0.058, slope_2: 0.028\n","    loss: 12.311, intercept: 0.109, slope_1: 0.059, slope_2: 0.029\n","    loss: 12.297, intercept: 0.110, slope_1: 0.060, slope_2: 0.030\n","~~~"]},{"attachments":{},"cell_type":"markdown","id":"9ceecb1c-cf05-464e-8b90-2fcf94da40eb","metadata":{},"source":["<img src=\"images/batch.png\" />"]},{"cell_type":"markdown","id":"4ff358ba-93dc-4376-b33b-c2dd6c3a2b89","metadata":{},"source":["## Preparing to batch train"]},{"cell_type":"code","execution_count":11,"id":"8511c841-3d30-40e2-8d31-139dc1882461","metadata":{"executionTime":39,"lastSuccessfullyExecutedCode":"# Define the intercept and slope\nintercept = tf.Variable(10.0, dtype=tf.float32)\nslope = tf.Variable(0.5, dtype=tf.float32)\n\n# Define the model\ndef linear_regression(intercept, slope, features):\n\t# Define the predicted values\n\treturn intercept + slope*features\n\n# Define the loss function\ndef loss_function(intercept, slope, targets, features):\n\t# Define the predicted values\n\tpredictions = linear_regression(intercept, slope, features)\n    \n \t# Define the MSE loss\n\treturn keras.losses.mse(targets, predictions)"},"outputs":[],"source":["# Define the intercept and slope\n","intercept = tf.Variable(10.0, dtype=tf.float32)\n","slope = tf.Variable(0.5, dtype=tf.float32)\n","\n","# Define the model\n","def linear_regression(intercept, slope, features):\n","\t# Define the predicted values\n","\treturn intercept + slope*features\n","\n","# Define the loss function\n","def loss_function(intercept, slope, targets, features):\n","\t# Define the predicted values\n","\tpredictions = linear_regression(intercept, slope, features)\n","    \n"," \t# Define the MSE loss\n","\treturn keras.losses.mse(targets, predictions)"]},{"cell_type":"markdown","id":"e4b88fcc-3d7c-4993-9a9c-08aebdf6e090","metadata":{},"source":["## Training a linear model in batches"]},{"cell_type":"code","execution_count":13,"id":"071d46bc-a54e-4dff-a6fb-77b50e9c0c7e","metadata":{"executionTime":896,"lastSuccessfullyExecutedCode":"intercept = tf.Variable(10.0, dtype=tf.float32)\nslope = tf.Variable(0.5, dtype=tf.float32)\n\n# Initialize Adam optimizer\nopt = keras.optimizers.Adam()\n\n# Load data in batches\nfor batch in pd.read_csv('datasets/kc_house_data.csv', chunksize=100):\n\tsize_batch = np.array(batch['sqft_lot'], np.float32)\n\n\t# Extract the price values for the current batch\n\tprice_batch = np.array(batch['price'], np.float32)\n\n\t# Complete the loss, fill in the variable list, and minimize\n\topt.minimize(lambda: loss_function(intercept, slope, price_batch, size_batch), var_list=[intercept, slope])\n\n# Print trained parameters\nprint(intercept.numpy(), slope.numpy())"},"outputs":[{"name":"stdout","output_type":"stream","text":["10.217888 0.7016001\n"]}],"source":["intercept = tf.Variable(10.0, dtype=tf.float32)\n","slope = tf.Variable(0.5, dtype=tf.float32)\n","\n","# Initialize Adam optimizer\n","opt = keras.optimizers.Adam()\n","\n","# Load data in batches\n","for batch in pd.read_csv('datasets/kc_house_data.csv', chunksize=100):\n","\tsize_batch = np.array(batch['sqft_lot'], np.float32)\n","\n","\t# Extract the price values for the current batch\n","\tprice_batch = np.array(batch['price'], np.float32)\n","\n","\t# Complete the loss, fill in the variable list, and minimize\n","\topt.minimize(lambda: loss_function(intercept, slope, price_batch, size_batch), var_list=[intercept, slope])\n","\n","# Print trained parameters\n","print(intercept.numpy(), slope.numpy())"]},{"cell_type":"markdown","id":"26359c1f-f6a2-412b-b66c-75999c30ef69","metadata":{},"source":["## The linear algebra of dense layers"]},{"cell_type":"code","execution_count":9,"id":"fddee642-1686-4b25-9591-57e67bca6f91","metadata":{"executionTime":18,"lastSuccessfullyExecutedCode":"# Define function\ndef Variable(x):\n    return(tf.Variable(x))\n\ndef matmul(x, y):\n    return(tf.matmul(x, y))\n\ndef ones(x):\n    return(tf.ones(x))"},"outputs":[],"source":["# From previous step\n","bias1 = Variable(1.0)\n","weights1 = Variable(ones((3, 2)))\n","product1 = matmul(borrower_features, weights1)\n","dense1 = keras.activations.sigmoid(product1 + bias1)\n","\n","# Initialize bias2 and weights2\n","bias2 = Variable(1.0)\n","weights2 = Variable(ones((2, 1)))\n","\n","# Perform matrix multiplication of dense1 and weights2\n","product2 = matmul(dense1, weights2)\n","\n","# Apply activation to product2 + bias2 and print the prediction\n","prediction = keras.activations.sigmoid(product2 + bias2)\n","print('\\n prediction: {}'.format(prediction.numpy()[0,0]))\n","print('\\n actual: 1')"]},{"cell_type":"markdown","id":"22428c5f-45a9-440d-abdf-d5057a376c17","metadata":{},"source":["result is\n","~~~ python\n","output:\n","    \n","     prediction: 0.9525741338729858\n","    \n","     actual: 1\n","~~~"]},{"attachments":{},"cell_type":"markdown","id":"f5049422-d03e-4df2-adf7-357f64262c5d","metadata":{},"source":["## The low-level approach with multiple examples <br> \n","We'll assume the model is trained and the first layer weights, `weights1`, and bias, `bias1`, are available. We'll then perform matrix multiplication of the `borrower_features` tensor by the `weights1` variable. Recall that the `borrower_features` tensor includes education, marital status, and age. Finally, we'll apply the sigmoid function to the elements of `products1 + bias1`, yielding `dense1`.\n","</br>\n","<img src=\"images/ex.png\" />"]},{"cell_type":"code","execution_count":null,"id":"da98708a-e39c-402e-bc04-7e2aa3a827b4","metadata":{},"outputs":[],"source":["# Compute the product of borrower_features and weights1\n","products1 = matmul(borrower_features, weights1)\n","\n","# Apply a sigmoid activation function to products1 + bias1\n","dense1 = keras.activations.sigmoid(products1 + bias1)\n","\n","# Print the shapes of borrower_features, weights1, bias1, and dense1\n","print('\\n shape of borrower_features: ', borrower_features.shape)\n","print('\\n shape of weights1: ', weights1.shape)\n","print('\\n shape of bias1: ', bias1.shape)\n","print('\\n shape of dense1: ', dense1.shape)"]},{"cell_type":"markdown","id":"98c96897-1db3-4d78-88de-d90dde9e079a","metadata":{},"source":["result is\n","~~~ python\n","output:\n","     shape of borrower_features:  (5, 3)\n","    \n","     shape of weights1:  (3, 2)\n","    \n","     shape of bias1:  (1,)\n","    \n","     shape of dense1:  (5, 2)\n","~~~"]},{"attachments":{},"cell_type":"markdown","id":"05124f92-cde6-44d4-849b-3899929c3e04","metadata":{},"source":["## Using the dense layer operation\n","This will allow us to construct the network below, which has 2 hidden layers and 10 features, using less code than we needed for the network with 1 hidden layer and 3 features. <br>\n","To construct this network, we'll need to define three dense layers, each of which takes the previous layer as an input, multiplies it by weights, and applies an activation function. Note that input data has been defined and is available as a 100x10 tensor: `borrower_features`.\n","</br>\n","<img src=\"images/dense-layer.png\" />"]},{"cell_type":"code","execution_count":null,"id":"2c4a29e6-a710-4a79-93c1-aa31a31d184b","metadata":{},"outputs":[],"source":["# Define the first dense layer\n","dense1 = keras.layers.Dense(7, activation='sigmoid')(borrower_features)\n","\n","# Define a dense layer with 3 output nodes\n","dense2 = keras.layers.Dense(3, activation='sigmoid')(dense1)\n","\n","# Define a dense layer with 1 output node\n","predictions = keras.layers.Dense(1, activation='sigmoid')(dense2)\n","\n","# Print the shapes of dense1, dense2, and predictions\n","print('\\n shape of dense1: ', dense1.shape)\n","print('\\n shape of dense2: ', dense2.shape)\n","print('\\n shape of predictions: ', predictions.shape)"]},{"cell_type":"markdown","id":"d7ca798d-c2e8-4de8-ae96-0015f997bbee","metadata":{},"source":["result is\n","~~~ python\n","output:\n","    \n","     shape of dense1:  (100, 7)\n","    \n","     shape of dense2:  (100, 3)\n","    \n","     shape of predictions:  (100, 1)\n","~~~"]},{"cell_type":"markdown","id":"7943874e-c030-47cb-a63c-57445d3e0133","metadata":{},"source":["## Binary classification problems"]},{"cell_type":"code","execution_count":null,"id":"1bd29893-51a0-4bf5-acb0-f2a8520c1ac1","metadata":{},"outputs":[],"source":["# Construct input layer from features\n","inputs = constant(bill_amounts)\n","\n","# Define first dense layer\n","dense1 = keras.layers.Dense(3, activation='relu')(inputs)\n","\n","# Define second dense layer\n","dense2 = keras.layers.Dense(2, activation='relu')(dense1)\n","\n","# Define output layer\n","outputs = keras.layers.Dense(1, activation='sigmoid')(dense2)\n","\n","# Print error for first five examples\n","error = default[:5] - outputs.numpy()[:5]\n","print(error)"]},{"cell_type":"markdown","id":"86f0e350-51a9-4ed6-9c5f-209d213d0589","metadata":{},"source":["result is\n","~~~ python\n","output:\n","    [[-1.]\n","     [-1.]\n","     [-1.]\n","     [-1.]\n","     [-1.]]\n","~~~"]},{"cell_type":"markdown","id":"c8014fb1-b71d-402a-9cce-e64acf03327b","metadata":{},"source":["## Multiclass classification problems"]},{"cell_type":"code","execution_count":null,"id":"7d10f431-7850-4c80-8818-36fcb38a6248","metadata":{},"outputs":[],"source":["# Construct input layer from borrower features\n","inputs = constant(borrower_features, float32)\n","\n","# Define first dense layer\n","dense1 = keras.layers.Dense(10, activation='sigmoid')(inputs)\n","\n","# Define second dense layer\n","dense2 = keras.layers.Dense(8, activation='relu')(dense1)\n","\n","# Define output layer\n","outputs = keras.layers.Dense(6, activation='softmax')(dense2)\n","\n","# Print first five predictions\n","print(outputs.numpy()[:5])"]},{"cell_type":"markdown","id":"b3580746-d161-4779-943f-8032553a662e","metadata":{},"source":["output:\n","    [[0.11941331 0.1677121  0.2684151  0.11520649 0.1298582  0.1993948 ]\n","     [0.0898606  0.22357854 0.1058039  0.15173064 0.18235849 0.24666782]\n","     [0.11727373 0.18521649 0.1905805  0.1730178  0.15243678 0.1814747 ]\n","     [0.10102767 0.1830875  0.17365667 0.13600807 0.1584808  0.24773929]\n","     [0.09415293 0.27197352 0.14801537 0.14544567 0.17041272 0.16999969]]"]},{"attachments":{},"cell_type":"markdown","id":"938a7e9a-c61e-431c-b3ff-cc901b21ee3e","metadata":{},"source":["## Simple problem\n","<img src=\"images/Simple-problem.png\"/>\n","\n","## The gradient descent optimizer\n","* Stochastic gradient descent (SGD) optimizer\n","    * tf.keras.optimizers.SGD()\n","    * learning_rate\n","* Simple and easy to interpret\n","\n","## The RMS prop optimizer\n","* Root mean squared (RMS) propagation optimizer\n","    * Applies different learning rates to each feature\n","    * tf.keras.optimizers.RMSprop()\n","    * learning_rate\n","    * momentum\n","    * decay\n","* Allows for momentum to both build and decay\n","\n","## The adam optimizer\n","* Adaptive moment (adam) optimizer\n","    * tf.keras.optimizers.Adam()\n","    * learning_rate\n","    * beta1\n","* Performs well with default parameter values\n","\n","## The dangers of local minima\n","Consider the plot of the following loss function, `loss_function()`, which contains a global minimum, marked by the dot on the right, and several local minima, including the one marked by the dot on the left. <br></br>\n","<img src=\"images/ex2.png\" width=\"400\" height=\"200\"> <br></br>\n","In this exercise, you will try to find the global minimum of `loss_function()` using `keras.optimizers.SGD()` You will do this twice, each time with a different initial value of the input to loss_function(). First, you will use `x_1`, which is a variable with an initial value of `6.0`. Second, you will use `x_2`, which is a variable with an initial value of `0.3`"]},{"cell_type":"code","execution_count":null,"id":"626d262b-7ac0-4513-bfc6-4d0995810534","metadata":{},"outputs":[],"source":["# Initialize x_1 and x_2\n","x_1 = Variable(6.0,float32)\n","x_2 = Variable(0.3,float32)\n","\n","# Define the optimization operation\n","opt = keras.optimizers.SGD(learning_rate=0.01)\n","\n","for j in range(100):\n","\t# Perform minimization using the loss function and x_1\n","\topt.minimize(lambda: loss_function(x_1), var_list=[x_1])\n","\t# Perform minimization using the loss function and x_2\n","\topt.minimize(lambda: loss_function(x_2), var_list=[x_2])\n","\n","# Print x_1 and x_2 as numpy arrays\n","print(x_1.numpy(), x_2.numpy())"]},{"cell_type":"markdown","id":"e189573e-8b17-4262-8a1c-e2c127e0c67b","metadata":{},"source":["result is\n","~~~ python\n","output:\n","    4.3801394 0.42052683\n","~~~\n","Notice that we used the same optimizer and loss function, but two different initial values. When we started at 6.0 with `x_1`, we found the global minimum at 4.38, marked by the dot on the right. When we started at 0.3, we stopped around 0.42 with `x_2`, the local minimum marked by a dot on the far left.\n","\n","## Avoiding local minima\n","The previous problem showed how easy it is to get stuck in local minima. We had a simple optimization problem in one variable and gradient descent still failed to deliver the global minimum when we had to travel through local minima first. One way to avoid this problem is to use momentum, which allows the optimizer to break through local minima."]},{"cell_type":"code","execution_count":null,"id":"fe1c0453-f254-4494-b5cf-2a1d36b06d10","metadata":{},"outputs":[],"source":["# Initialize x_1 and x_2\n","x_1 = Variable(0.05,float32)\n","x_2 = Variable(0.05,float32)\n","\n","# Define the optimization operation for opt_1 and opt_2\n","opt_1 = keras.optimizers.RMSprop(learning_rate=0.01, momentum=0.99)\n","opt_2 = keras.optimizers.RMSprop(learning_rate=0.01, momentum=0.00)\n","\n","for j in range(100):\n","\t# Define the minimization operation for opt_1\n","\topt_1.minimize(lambda: loss_function(x_1), var_list=[x_1])\n","    # Define the minimization operation for opt_2\n","\topt_2.minimize(lambda: loss_function(x_2), var_list=[x_2])\n","\n","# Print x_1 and x_2 as numpy arrays\n","print(x_1.numpy(), x_2.numpy())"]},{"cell_type":"markdown","id":"2f452f20-a99c-4a86-858c-aa20c1f5af26","metadata":{},"source":["result is\n","~~~ python\n","output:\n","    4.3150263 0.4205261\n","~~~\n","Recall that the global minimum is approximately 4.38. Notice that `opt_1` built momentum, bringing `x_1` closer to the global minimum. To the contrary, `opt_2`, which had a `momentum` parameter of 0.0, got stuck in the local minimum on the left.\n","\n","## Initialization in TensorFlow\n","A good initialization can reduce the amount of time needed to find the global minimum. In this exercise, we will initialize weights and biases for a neural network that will be used to predict credit card default decisions. To build intuition, we will use the low-level, linear algebraic approach, rather than making use of convenience functions and high-level keras operations. We will also expand the set of input features from 3 to 23."]},{"cell_type":"code","execution_count":null,"id":"3a30351c-7529-4704-92b1-1d45ce027c66","metadata":{},"outputs":[],"source":["# Define the layer 1 weights with shape [23, 7]\n","w1 = Variable(random.normal([23, 7]))\n","\n","# Initialize the layer 1 bias using ones\n","b1 = Variable(ones([7]))\n","\n","# Define the layer 2 weights with shape [7, 1]\n","w2 = Variable(random.normal([7, 1]))\n","\n","# Define the layer 2 bias and set its initial value to 0\n","b2 = Variable(0)"]},{"cell_type":"markdown","id":"7649f9bb-9ef7-485b-a755-e59dcdc1599c","metadata":{},"source":["## Defining the model and loss function\n","Train a neural network to predict whether a credit card holder will default."]},{"cell_type":"code","execution_count":null,"id":"01b2cc32-cacc-49d3-bf7a-c8e3fdac0ece","metadata":{},"outputs":[],"source":["# Define the model\n","def model(w1, b1, w2, b2, features = borrower_features):\n","\t# Apply relu activation functions to layer 1\n","\tlayer1 = keras.activations.relu(matmul(features, w1) + b1)\n","    # Apply dropout rate of 0.25\n","\tdropout = keras.layers.Dropout(0.25)(layer1)\n","\treturn keras.activations.sigmoid(matmul(dropout, w2) + b2)\n","\n","# Define the loss function\n","def loss_function(w1, b1, w2, b2, features = borrower_features, targets = default):\n","\tpredictions = model(w1, b1, w2, b2)\n","\t# Pass targets and predictions to the cross entropy loss\n","\treturn keras.losses.binary_crossentropy(targets, predictions)"]},{"cell_type":"markdown","id":"26cecacc-5688-4c43-94c8-12d01b1c3b05","metadata":{},"source":["## Training neural networks with TensorFlow\n","Train the model and then evaluate its performance by predicting default outcomes in a test set,"]},{"cell_type":"code","execution_count":null,"id":"d9be5c31-1f6d-4267-9a70-505102ee85f9","metadata":{},"outputs":[],"source":["# Train the model\n","for j in range(100):\n","    # Complete the optimizer\n","\topt.minimize(lambda: loss_function(w1, b1, w2, b2), \n","                 var_list=[w1, b1, w2, b2])\n","\n","# Make predictions with model using test features\n","model_predictions = model(w1, b1, w2, b2, test_features)\n","\n","# Construct the confusion matrix\n","confusion_matrix(test_targets, model_predictions)"]},{"attachments":{},"cell_type":"markdown","id":"59e54650-7eba-4d26-a754-8f32a2fdbe88","metadata":{},"source":["result is <br></br>\n","<img src=\"images/confusion-matrix.png\" width=\"400\" height=\"400\"> <br></br>\n","The diagonal elements show the number of correct predictions. The off-diagonal elements show the number of incorrect predictions. We can see that the model performs reasonably-well, but does so by overpredicting non-default. This suggests that we may need to train longer, tune the model's hyperparameters, or change the model's architecture."]},{"cell_type":"markdown","id":"01fb42ab-bfb6-41c0-b7e6-f75ced98a4e9","metadata":{},"source":["# Chapter 4 : High Level APIs\n","## The sequential model in Keras\n","In this exercise, you will use the `keras` sequential model API to define a neural network that can be used to classify images of sign language letters <br></br>\n","Note that the images were reshaped from (28, 28) to (784,), so that they could be used as inputs to a dense layer."]},{"cell_type":"code","execution_count":5,"id":"e7480e25-f3b5-4189-88aa-4af1f336da3a","metadata":{"executionTime":363,"lastSuccessfullyExecutedCode":"# Define a Keras sequential model\nmodel = keras.Sequential()\n\n# Define the first dense layer\nmodel.add(keras.layers.Dense(16, activation='relu', input_shape=(784,)))\n\n# Define the second dense layer\nmodel.add(keras.layers.Dense(8, activation='relu', input_shape=(784,)))\n\n# Define the output layer\nmodel.add(keras.layers.Dense(4, activation='softmax'))\n\n# Print the model architecture\nprint(model.summary())"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_3 (Dense)             (None, 16)                12560     \n","                                                                 \n"," dense_4 (Dense)             (None, 8)                 136       \n","                                                                 \n"," dense_5 (Dense)             (None, 4)                 36        \n","                                                                 \n","=================================================================\n","Total params: 12,732\n","Trainable params: 12,732\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"]}],"source":["# Define a Keras sequential model\n","model = keras.Sequential()\n","\n","# Define the first dense layer\n","model.add(keras.layers.Dense(16, activation='relu', input_shape=(784,)))\n","\n","# Define the second dense layer\n","model.add(keras.layers.Dense(8, activation='relu', input_shape=(784,)))\n","\n","# Define the output layer\n","model.add(keras.layers.Dense(4, activation='softmax'))\n","\n","# Print the model architecture\n","print(model.summary())"]},{"cell_type":"markdown","id":"ea08ec30-c945-4330-8bd8-d9881a49cb3d","metadata":{},"source":["## Compiling a sequential model\n","You will adopt a different network architecture than what you used in the previous exercise. There will be fewer layers, but more nodes. You will also apply dropout to prevent overfitting. "]},{"cell_type":"code","execution_count":6,"id":"89b4876b-8dee-40b6-9f1e-afaf6e36dd24","metadata":{"executionTime":410,"lastSuccessfullyExecutedCode":"# Define the first dense layer\nmodel.add(keras.layers.Dense(16, activation='sigmoid', input_shape=(784,)))\n\n# Apply dropout to the first layer's output\nmodel.add(keras.layers.Dropout(0.25))\n\n# Define the output layer\nmodel.add(keras.layers.Dense(4, activation='softmax'))\n\n# Compile the model\nmodel.compile('adam', loss='categorical_crossentropy')\n\n# Print a model summary\nprint(model.summary())"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_3 (Dense)             (None, 16)                12560     \n","                                                                 \n"," dense_4 (Dense)             (None, 8)                 136       \n","                                                                 \n"," dense_5 (Dense)             (None, 4)                 36        \n","                                                                 \n"," dense_6 (Dense)             (None, 16)                80        \n","                                                                 \n"," dropout (Dropout)           (None, 16)                0         \n","                                                                 \n"," dense_7 (Dense)             (None, 4)                 68        \n","                                                                 \n","=================================================================\n","Total params: 12,880\n","Trainable params: 12,880\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"]}],"source":["# Define the first dense layer\n","model.add(keras.layers.Dense(16, activation='sigmoid', input_shape=(784,)))\n","\n","# Apply dropout to the first layer's output\n","model.add(keras.layers.Dropout(0.25))\n","\n","# Define the output layer\n","model.add(keras.layers.Dense(4, activation='softmax'))\n","\n","# Compile the model\n","model.compile('adam', loss='categorical_crossentropy')\n","\n","# Print a model summary\n","print(model.summary())"]},{"cell_type":"markdown","id":"2a045d16-163c-44bf-9d93-e5e892be35de","metadata":{},"source":["## Defining a multiple input model\n","In some cases, the sequential API will not be sufficiently flexible to accommodate your desired model architecture and you will need to use the functional API instead. If, for instance, you want to train two models with different architectures jointly, you will need to use the functional API to do this."]},{"cell_type":"code","execution_count":null,"id":"fa22deee-6d7b-43da-9c34-7797fa393ba1","metadata":{},"outputs":[],"source":["# For model 1, pass the input layer to layer 1 and layer 1 to layer 2\n","m1_layer1 = keras.layers.Dense(12, activation='sigmoid')(m1_inputs)\n","m1_layer2 = keras.layers.Dense(4, activation='softmax')(m1_layer1)\n","\n","# For model 2, pass the input layer to layer 1 and layer 1 to layer 2\n","m2_layer1 = keras.layers.Dense(12, activation='relu')(m2_inputs)\n","m2_layer2 = keras.layers.Dense(4, activation='softmax')(m2_layer1)\n","\n","# Merge model outputs and define a functional model\n","merged = keras.layers.add([m1_layer2, m2_layer2])\n","model = keras.Model(inputs=[m1_inputs, m2_inputs], outputs=merged)\n","\n","# Print a model summary\n","print(model.summary())"]},{"cell_type":"markdown","id":"a111d08a-ff78-43c6-a041-305f7d95e216","metadata":{},"source":["result is\n","~~~ python\n","output:\n","    Model: \"model\"\n","    __________________________________________________________________________________________________\n","    Layer (type)                    Output Shape         Param #     Connected to                     \n","    ==================================================================================================\n","    input_1 (InputLayer)            [(None, 784)]        0                                            \n","    __________________________________________________________________________________________________\n","    input_2 (InputLayer)            [(None, 784)]        0                                            \n","    __________________________________________________________________________________________________\n","    dense (Dense)                   (None, 12)           9420        input_1[0][0]                    \n","    __________________________________________________________________________________________________\n","    dense_2 (Dense)                 (None, 12)           9420        input_2[0][0]                    \n","    __________________________________________________________________________________________________\n","    dense_1 (Dense)                 (None, 4)            52          dense[0][0]                      \n","    __________________________________________________________________________________________________\n","    dense_3 (Dense)                 (None, 4)            52          dense_2[0][0]                    \n","    __________________________________________________________________________________________________\n","    add (Add)                       (None, 4)            0           dense_1[0][0]                    \n","                                                                     dense_3[0][0]                    \n","    ==================================================================================================\n","    Total params: 18,944\n","    Trainable params: 18,944\n","    Non-trainable params: 0\n","    __________________________________________________________________________________________________\n","    None\n","~~~\n","\n","Notice that the `.summary()` method yields a new column: `connected to`. This column tells you how layers connect to each other within the network. We can see that `dense_2`, for instance, is connected to the `input_2` layer. We can also see that the `add` layer, which merged the two models, connected to both `dense_1` and `dense_3`."]},{"cell_type":"markdown","id":"0d312814-d19f-43af-9f7e-dba34f74b849","metadata":{},"source":["## Training with Keras\n","In this exercise, we return to our sign language letter classification problem. We have 2000 images of four letters A, B, C, and D and we want to classify them with a high level of accuracy. We will complete all parts of the problem, including the model definition, compilation, and training."]},{"cell_type":"code","execution_count":null,"id":"07fa13ee-54a6-44d3-b1b5-8d4126bdc55e","metadata":{},"outputs":[],"source":["# Define a sequential model\n","model = keras.Sequential()\n","\n","# Define a hidden layer\n","model.add(keras.layers.Dense(16, activation='relu', input_shape=(784,)))\n","\n","# Define the output layer\n","model.add(keras.layers.Dense(4, activation='softmax'))\n","\n","# Compile the model\n","model.compile('SGD', loss='categorical_crossentropy')\n","\n","# Complete the fitting operation\n","model.fit(sign_language_features, sign_language_labels, epochs=5)"]},{"cell_type":"markdown","id":"a91346f3-da4f-45a9-bb65-35b7dc11484b","metadata":{},"source":["## Metrics and validation with Keras"]},{"cell_type":"code","execution_count":null,"id":"870f833e-357c-4624-82af-1d3526206ca0","metadata":{},"outputs":[],"source":["# Define sequential model\n","model = keras.Sequential()\n","\n","# Define the first layer\n","model.add(keras.layers.Dense(32, activation='sigmoid', input_shape=(784,)))\n","\n","# Add activation function to classifier\n","model.add(keras.layers.Dense(4, activation='softmax'))\n","\n","# Set the optimizer, loss function, and metrics\n","model.compile(optimizer='RMSprop', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Add the number of epochs and the validation split\n","model.fit(sign_language_features, sign_language_labels, epochs=10, validation_split=0.1)"]},{"cell_type":"markdown","id":"6ebc458b-02a3-427f-aaa2-8916548e1a7c","metadata":{},"source":["## Overfitting detection"]},{"cell_type":"code","execution_count":null,"id":"f7fe2e0f-bac9-4af5-88fe-44a49e0e8b59","metadata":{},"outputs":[],"source":["# Define sequential model\n","model = keras.Sequential()\n","\n","# Define the first layer\n","model.add(keras.layers.Dense(1024, activation='relu', input_shape=(784,)))\n","\n","# Add activation function to classifier\n","model.add(keras.layers.Dense(4, activation='softmax'))\n","\n","# Finish the model compilation\n","model.compile(optimizer=keras.optimizers.Adam(lr=0.001), \n","              loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Complete the model fit operation\n","model.fit(sign_language_features, sign_language_labels, epochs=50, validation_split=0.5)"]},{"cell_type":"markdown","id":"7fcd2af8-066a-4111-a5c5-f47d8a67dc0e","metadata":{},"source":["## Evaluating models"]},{"cell_type":"code","execution_count":null,"id":"efd7e434-77c6-45fb-9c4c-02b2a8dbd457","metadata":{},"outputs":[],"source":["# Evaluate the small model using the train data\n","small_train = small_model.evaluate(train_features, train_labels)\n","\n","# Evaluate the small model using the test data\n","small_test = small_model.evaluate(test_features, test_labels)\n","\n","# Evaluate the large model using the train data\n","large_train = large_model.evaluate(train_features, train_labels)\n","\n","# Evaluate the large model using the test data\n","large_test = large_model.evaluate(test_features, test_labels)\n","\n","# Print losses\n","print('\\n Small - Train: {}, Test: {}'.format(small_train, small_test))\n","print('Large - Train: {}, Test: {}'.format(large_train, large_test))"]},{"cell_type":"markdown","id":"385deb82-b2bd-4164-a290-f5cd282f3b43","metadata":{},"source":["## Preparing to train with Estimators\n","For this exercise, we'll return to the King County housing transaction dataset from chapter 2. We will again develop and train a machine learning model to predict house prices; however, this time, we'll do it using the `estimator` API"]},{"cell_type":"code","execution_count":null,"id":"1109be6d-9d97-4898-979c-08e7bab14f9b","metadata":{},"outputs":[],"source":["# Define feature columns for bedrooms and bathrooms\n","bedrooms = feature_column.numeric_column(\"bedrooms\")\n","bathrooms = feature_column.numeric_column(\"bathrooms\")\n","\n","# Define the list of feature columns\n","feature_list = [bedrooms, bathrooms]\n","\n","def input_fn():\n","\t# Define the labels\n","\tlabels = np.array(housing['price'])\n","\t# Define the features\n","\tfeatures = {'bedrooms':np.array(housing['bedrooms']), \n","                'bathrooms':np.array(housing['bathrooms'])}\n","\treturn features, labels"]},{"cell_type":"markdown","id":"099c2f36-79e0-482a-9003-c49c41e8c7a8","metadata":{},"source":["## Defining Estimators\n","In this exercise, you will build on that work by defining an `estimator` that makes use of input data. <br></br>\n","Use a deep neural network regressor with 2 nodes in both the first and second hidden layers and 1 training step."]},{"cell_type":"code","execution_count":null,"id":"623ede8c-35b5-4c58-9ceb-e902022839b5","metadata":{},"outputs":[],"source":["# Define the model and set the number of steps\n","model = estimator.DNNRegressor(feature_columns=feature_list, hidden_units=[2,2])\n","model.train(input_fn, steps=1)"]},{"cell_type":"markdown","id":"3ff43ef8-d511-4871-84f0-444a8f940f2e","metadata":{},"source":["Modify the code to use a `LinearRegressor()`, remove the `hidden_units`, and set the number of `steps` to 2."]},{"cell_type":"code","execution_count":null,"id":"632372ed-65e1-4568-80c1-ca49de06c699","metadata":{},"outputs":[],"source":["# Define the model and set the number of steps\n","model = estimator.LinearRegressor(feature_columns=feature_list)\n","model.train(input_fn, steps=2)"]},{"cell_type":"markdown","id":"3818715d-017b-405e-a049-ed33f8da9d39","metadata":{},"source":["# What i have learned\n","* <b>Chapter 1</b>\n","    * Low-level, basic and advanced operations\n","    * Graph-based computation\n","    * Gradient computation and optimization\n","* <b>Chapter 2</b>\n","    * Data loading and transformation\n","    * Predefined and custom loss functions\n","    * Linear models and batch training\n","* <b>Chapter 3</b>\n","    * Dense neural network layers\n","    * Activation functions\n","    * Optimization algorithms\n","    * Training neural networks\n","* <b>Chapter 4</b>\n","    * Neural networks in Keras\n","    * Training and validation\n","    * The Estimators API"]}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"editor":"DataCamp Workspace","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":5}
