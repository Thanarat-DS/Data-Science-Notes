{"cells":[{"source":"# Introduction to Deep Learning with Kera","metadata":{},"id":"7607bdb2-1707-4361-a984-1c443fe84370","cell_type":"markdown"},{"source":"# Import any packages you want to use here\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense","metadata":{"executionTime":30,"lastSuccessfullyExecutedCode":"# Import any packages you want to use here\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense"},"id":"7f26dd6a-20aa-4d19-8d3f-b8f64fba1821","cell_type":"code","execution_count":3,"outputs":[]},{"source":"# Chapter 1 : Introducing Keras\n\n## Theano vs Keras\n<img src=\"images/VS.png\" width=\"800\" height=\"600\">\n\nTheano\n* Building a neural network in Theano can take many lines of codes and requires a deep understanding of how they work internally.\nKeras\n* Building and training this very same network in Keras only takes a few lines of code.\n\n## Keras\n* Deep Learning Framework\n* Enables fast experimentation\n* Runs on top of other frameworks\n* Wrtten by Fran√ßois Chollet\n\n## Why use Keras?\n* Fast industry-ready models\n* For beginners and experts\n* Less code \n* Build any architecture\n* Deploy models in multiple platforms like Android, iOS, web-apps, etc\n\n<img src=\"images/VS2.png\" width=\"200\" height=\"200\">\n\n## Keras + TensorFlow\n* TensorFlow's high level framework of choice\n* Keras is complementary to TensorFlow\n* You can use TensorFlow for low level features\n\n## Feature Engineering\n<img src=\"images/ML_vs_DL.png\">\n\nDeep Learning\n* Neural networks are good feature extractors, since they learn the best way to make sense of <b>unstuctured data</b>\n* Neural networks can learn the best features and their combination, they can perform feature engineearing themselves\n\n## Hello nets!\nYou will build a network that takes two numbers as an input, passes them through a hidden layer of 10 neurons, and finally outputs a single non-constrained number.\n\nA non-constrained output can be obtained by avoiding setting an activation function in the output layer. This is useful for problems like regression, when we want our output to be able to take any non-constrained value.\n\n<img src=\"images/neural.png\" />","metadata":{},"id":"a0ac303b-ad44-4690-a9f0-a70619fcabc4","cell_type":"markdown"},{"source":"# Import the Sequential model and Dense layer\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\n# Create a Sequential model\nmodel = Sequential()\n\n# Add an input layer and a hidden layer with 10 neurons\nmodel.add(Dense(10, input_shape=(2,), activation=\"relu\"))\n\n# Add a 1-neuron output layer\nmodel.add(Dense(1))\n\n# Summarise your model\nmodel.summary()","metadata":{"executionTime":319,"lastSuccessfullyExecutedCode":"# Import the Sequential model and Dense layer\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\n# Create a Sequential model\nmodel = Sequential()\n\n# Add an input layer and a hidden layer with 10 neurons\nmodel.add(Dense(10, input_shape=(2,), activation=\"relu\"))\n\n# Add a 1-neuron output layer\nmodel.add(Dense(1))\n\n# Summarise your model\nmodel.summary()"},"id":"7869e914-9bb1-4f2d-a48b-5ab87e36e9b7","cell_type":"code","execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":"Model: \"sequential_1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n dense_2 (Dense)             (None, 10)                30        \n                                                                 \n dense_3 (Dense)             (None, 1)                 11        \n                                                                 \n=================================================================\nTotal params: 41\nTrainable params: 41\nNon-trainable params: 0\n_________________________________________________________________\n"}]},{"source":"## Specifying a model\nYou will build a simple regression model to predict the orbit of the meteor!\n\nYour training data consist of measurements taken at time steps from -10 minutes before the impact region to +10 minutes after. Each time step can be viewed as an X coordinate in our graph, which has an associated position Y for the meteor orbit at that time step.\n\nNote that you can view this problem as approximating a quadratic function via the use of neural networks.\n\n<img src=\"images/ex.png\" width=400 \n     height=400/>\n     \nThis data is stored in two numpy arrays: one called `time_steps` , what we call features, and another called `y_positions`, with the labels. Go on and build your model! It should be able to predict the y positions for the meteor orbit at future time steps.","metadata":{},"cell_type":"markdown","id":"2377e5f0-59d6-4b68-8d97-938f5a2daa25"},{"source":"# Instantiate a Sequential model\nmodel = Sequential()\n\n# Add a Dense layer with 50 neurons and an input of 1 neuron\nmodel.add(Dense(50, input_shape=(1,), activation='relu'))\n\n# Add two Dense layers with 50 neurons and relu activation\nmodel.add(Dense(50,activation='relu'))\nmodel.add(Dense(50,activation='relu'))\n\n# End your model with a Dense layer and no activation\nmodel.add(Dense(1))","metadata":{"executionTime":28,"lastSuccessfullyExecutedCode":"# Instantiate a Sequential model\nmodel = Sequential()\n\n# Add a Dense layer with 50 neurons and an input of 1 neuron\nmodel.add(Dense(50, input_shape=(1,), activation='relu'))\n\n# Add two Dense layers with 50 neurons and relu activation\nmodel.add(Dense(50,activation='relu'))\nmodel.add(Dense(50,activation='relu'))\n\n# End your model with a Dense layer and no activation\nmodel.add(Dense(1))"},"cell_type":"code","id":"213a30a4-9c11-493a-9b00-dad8313708ff","execution_count":5,"outputs":[]},{"source":"You are closer to forecasting the meteor orbit! It's important to note we aren't using an activation function in our output layer since `y_positions` aren't bounded and they can take any value. Your model is built to perform a regression task.\n\n## Training","metadata":{},"cell_type":"markdown","id":"8264ef91-196c-409b-a49f-ae18abadf2e0"},{"source":"# Compile your model\nmodel.compile(optimizer = 'adam', loss = 'mse')\n\nprint(\"Training started..., this can take a while:\")\n\n# Fit your model on your data for 30 epochs\nmodel.fit(time_steps,y_positions, epochs = 30)\n\n# Evaluate your model \nprint(\"Final loss value:\",model.evaluate(time_steps, y_positions))","metadata":{},"cell_type":"code","id":"2ba7cd0a-e976-4dac-b5d0-9a4e122b3573","execution_count":null,"outputs":[]},{"source":"## Predicting the orbit!\nYou've already trained a `model` that approximates the orbit of the meteor approaching Earth and it's loaded for you to use.\n\nSince you trained your model for values between -10 and 10 minutes, your model hasn't yet seen any other values for different time steps. You will now visualize how your model behaves on unseen data.\n\nIf you want to check the source code of `plot_orbit`, paste `show_code(plot_orbit)` into the console.\n\nshow_code(plot_orbit)\n~~~ python\ndef plot_orbit(model_preds):\n  axeslim = int(len(model_preds)/2)\n  plt.plot(np.arange(-axeslim, axeslim + 1),np.arange(-axeslim, axeslim + 1)**2,color=\"mediumslateblue\")\n  plt.plot(np.arange(-axeslim, axeslim + 1),model_preds,color=\"orange\")\n  plt.axis([-40, 41, -5, 550])\n  plt.legend([\"Scientist's Orbit\", 'Your orbit'],loc=\"lower left\")\n  plt.title(\"Predicted orbit vs Scientist's Orbit\")\n  plt.show()\n~~~\n\nHurry up, the Earth is running out of time!\n<br></br>\n\nUse the model's `.predict()` method to predict from `-10` to `10` minutes.","metadata":{},"cell_type":"markdown","id":"ab122e14-822a-4af8-af8a-6391b64bdd83"},{"source":"# Predict the twenty minutes orbit\ntwenty_min_orbit = model.predict(np.arange(-10, 11))\n\n# Plot the twenty minute orbit \nplot_orbit(twenty_min_orbit)","metadata":{},"cell_type":"code","id":"23dc5874-2481-4903-804d-d8d8f1932ff2","execution_count":null,"outputs":[]},{"source":"<img src=\"images/-10_10.png\" width=\"500\" height=\"500\" />\n<br></br>\n\nUse the model's `.predict()` method to predict from `-40` to `40` minutes.","metadata":{},"cell_type":"markdown","id":"04fdd5c0-769a-4cb3-b4f6-84c640c37ab0"},{"source":"# Predict the eighty minute orbit\neighty_min_orbit = model.predict(np.arange(-40, 41))\n\n# Plot the eighty minute orbit \nplot_orbit(eighty_min_orbit)","metadata":{},"cell_type":"code","id":"60b6c28e-06ac-481b-89f2-a0d4a8e8a88b","execution_count":null,"outputs":[]},{"source":"<img src=\"images/-40_40.png\" width=\"500\" height=\"500\" />\n\nYour model fits perfectly to the scientists trajectory for time values between -10 to +10, the region where the meteor crosses the impact region, so we won't be hit! However, it starts to diverge when predicting for new values we haven't trained for. This shows neural networks learn according to the data they are fed with. Data quality and diversity are very important. ","metadata":{},"cell_type":"markdown","id":"2141be67-0d01-4bd5-a259-383ed7f5a2eb"},{"source":"# Chapter 2 : Going Deeper\n","metadata":{},"cell_type":"markdown","id":"9200a18f-1798-47ae-be40-6663f13dfaf8"},{"source":"## When to use binary classification?\n<img src=\"images/Binary.png\" />","metadata":{},"cell_type":"markdown","id":"4d4280b3-670a-4714-9d3f-a0f21b9e1ead"}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.8.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"editor":"DataCamp Workspace"},"nbformat":4,"nbformat_minor":5}